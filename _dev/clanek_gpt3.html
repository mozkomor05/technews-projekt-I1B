<p><strong>GPT-3</strong> (<em>Generative Pre-trained Transformer 3</em>) je umělá neuronová síť napodobující lidský
    jazyk. Vytváří jazykový model, který má za úkol klasifikovat a vytvářet obsah. Člověk jí dá kus textu, ona podle
    svých znalostí jazyka z obřího korpusu odhaduje pravděpodobné pokračování. GPT-3 je zdaleka největší síť svého druhu
    na světě. Vytvořila ji kalifornská společnost <strong>OpenAI</strong>, která by jednou ráda přišla s autonomní
    umělou inteligencí, ze které bude &bdquo;těžit celé lidstvo&ldquo;. </p>
<p> Jedna a ta samá neuronová síť dokáže nabídnout na základě jednoduchých dotazů <a
        href="https://twitter.com/QasimMunye/status/1278750809094750211">lékařskou
    diagnózu</a>, sepsat <a href="https://twitter.com/DonCubed/status/1284908940149395456?s=20">fešný životopis</a> i <a
        href="https://twitter.com/OthersideAI/status/1285776335638614017">zdvořilý e-mail</a> z pár odrážek, rozprávět
    <a href="https://twitter.com/Merzmensch/status/1283419366143524866?s=20">o Bohu</a> i <a
            href="https://twitter.com/Siddharth87/status/1283920116007092224?s=20">smyslu života</a>, <a
            href="https://twitter.com/paraschopra/status/1284801028676653060?s=20">odpovědět na cokoliv</a>, simulovat
    <a href="https://www.aiwriter.email">názory i dávno</a><a href="https://www.aiwriter.email"> mrtvých lidí</a>,
    zjednodušovat text <a href="https://andrewmayneblog.wordpress.com/2020/06/13/openai-api-alchemy-summarization/">na
        úroveň druháka</a> stejně jako učinit srozumitelným <a
            href="https://www.artificiallawyer.com/2020/07/29/gpt-3-a-game-changer-for-legal-tech/">právnický jazyk</a>,
    psát <a href="https://www.gwern.net/GPT-3">prózu i poezii</a>, vyseknout <a
            href="https://www.theverge.com/2020/8/16/21371049/gpt3-hacker-news-ai-blog">populární blogový příspěvek</a>,
    generovat <a href="https://play.aidungeon.io/">textové hry</a> stejně jako <a
            href="https://twitter.com/sharifshameem/status/1282676454690451457?s=20">navrhovat šablony webů</a> a <a
            href="https://twitter.com/jsngr/status/1284511080715362304">rozhraní aplikací</a>, protože za nimi je v
    posledku také text. A to všechno s výsledky až nepříjemně nerozeznatelnými od výtvorů skutečných lidí.
</p>
<p> Skutečný průlom v oblasti umělé inteligence, nic tak zajímavého jsme tu ještě neměli, <a
        href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential">říkají jedni</a>.
    Podobné systémy už pár let máme, algoritmus jen zmohutněl a zpřesnil, přesto pořád dělá vyloženě dětinské chyby, <a
            href="https://www.forbes.com/sites/robtoews/2020/07/19/gpt-3-is-amazingand-overhyped/#6283c8201b1c">namítají</a>
    <a href="https://minimaxir.com/2020/07/gpt3-expectations/">druzí</a>. Že je humbuk v IT kruzích až příliš velký,
    upozornil i Sam Altman, CEO společnosti OpenAI, která za modelem zvaným GPT-3 stojí. Umělá inteligence podle něho
    změní svět, GPT-3 je ale pouze náznakem možného, <a href="https://twitter.com/sama/status/1284922296348454913?s=20">tweetoval</a>
    otec zakladatel. </p>
<p> Za pozornost ale tahle doposud největší neuronová síť pro jazykové modely rozhodně stojí. Stejně jako etické otázky
    s ní spojené. Řada odborníků včetně inženýrů z OpenAI varuje před potenciálními riziky tohoto systému. Stejně jako
    psaní poutavých textů dokáže se svými hlubšími znalostmi totiž velice jednoduše vyjádřit i projevy nenávisti,
    rasismu či sexismu. &bdquo;To, co dnes máme, jsou jenom ústa bez mozku,&ldquo; uvedl jeden z vědců. Kdyby se tato
    technologie dostala do rukou extrémistických skupin, mohla by zautomatizovat produkci nenávistného obsahu. Cílem
    vědců již tedy není větší plynulost jazyka, nýbrž zajištění bezpečnějšího užívání tohoto systému. </p>
<figure class="figure">
    <img src="/assets/img/uploads/gpt-3-versus-the-others.jpg" class="figure-img img-fluid rounded" alt="GTP-3 versus předchozí modely">
    <figcaption class="figure-caption text-center">GPT-3 (modrá čára) oproti předchozím modelům. GPT-3 se mj. chlubí svou vysokou "zeo shot" přesností.</figcaption>
</figure>
<h3>GPT-3 nerozumí textu, takže nedokáže napsat článek, že?</h3>
<em>Ne tak docela.</em>
<p>Minulý rok se student Kalifornské univerzity Liam Porr snažil dokázat, že se umělá inteligence může uplatnit jako
    lidský spisovatel, a provedl experiment. Věřil, že obsah produkovaný GPT-3 může lidi oklamat natolik, aby věřili, že
    byl vytvořen člověkem, a založil blog, na kterém tento obsah zveřejňoval. Jeden z <a
            href="https://www.technologyreview.com/2020/08/14/1006780/ai-gpt-3-fake-blog-reached-top-of-hacker-news/">příspěvků</a>
    se dokonce umístil na prvním místě na Hacker News. A vskutku jen málokdo poznal, že tyto příspěvky nepsala lidská
    ruka. &bdquo;Ve skutečnosti to bylo velice snadné,&ldquo; řekl pro MIT Technology Review, &bdquo;což je ta děsivá
    část.&ldquo;</p>
<p>V září roku 2020 vydal britský deník The Guardian článek s názvem <a
        href="https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3"><em>Celý tento
    článek napsal robot. Už se bojíš, člověče?</em></a> Na úvod bylo řečeno, že k vytvoření tohoto článku byla využita
    technologie GPT-3, která dostala za úkol přesvědčit lidstvo o tom, že roboti přicházejí v míru. Výsledný text byl
    prakticky nerozlišitelný od takového, který by dokázal napsat člověk, a není tedy divu, že po svém vydání způsobil
    ve světě ohlas. Nicméně v poznámce redakce stálo, že tento článek nebyl tak úplně celý napsán počítačem, jak se ze
    začátku tvářil. Deník zde popisoval instrukce, které byly GPT-3 dány, zahrnujíc délku článku, styl psaní, jazyk a
    také úvodní věty celého textu. Poté uvedl, že systém vytvořil celkem osm různých článků, ze kterých byly dle názoru
    redakce vyjmuty nejlepší části a následně poskládány do jednoho výsledného textu. Nakonec dodal, že úprava počítačem
    napsaného článku se nijak nelišila od úpravy článků napsaných lidmi, ba dokonce možná zabrala i méně času.
</p>
<p>Na tento počin se záhy strhla vlna <a href="https://bdtechtalks.com/2020/09/14/guardian-gpt-3-article-ai-fake-news/">kritiky</a>.
    Některá média označila článek za zavádějící či s neúplnými informacemi. Navíc tím, že vydaný text byl upravený a
    poskládaný z různých částí svých několika verzí, nepřinášel čtenáři ani relevantní představu o tom, jak umělá
    inteligence doopravdy umí psát.</p>
<p>Nápadu vydávat texty napsané umělou inteligencí se v prosinci roku 2020 chytil také časopis Wired, který využil GPT-3
    k vytvoření královnina každoročního vánočního projevu. GPT-3 měl ovšem znalosti jen z doby předpandemické, největším
    oříškem proto bylo ho přimět, aby se vyjadřoval k aktuálnímu dění ve světě. Časopis nakonec zveřejnil celkem <a
            href="https://www.wired.co.uk/article/ai-queens-speech-christmas-day">tři různé
        projevy</a>, čím dál propracovanější a učesanější, vždy s vlastním komentářem. Avšak ani po přečtení posledního
    a nejlepšího z nich neuznal, že by umělá inteligence dokázala plně nahradit lidského autora. Přestože syntax byla
    téměř dokonalá, systém několikrát vygeneroval nenávistné a pobuřující fráze, které bylo nutno z projevu odstranit.
</p>
<p>S publikacemi napsanými umělou inteligencí se bezpochyby budeme setkávat čím dál častěji, nicméně novináři se jeho
    případnému <a
            href="https://www.forbes.com/sites/nicolemartin1/2019/02/08/did-a-robot-write-this-how-ai-is-impacting-journalism/?sh=2da0a8f47795">využití
        v žurnalistice</a> obávají. Tvrdí, že obsah vytvořený umělou inteligencí by mohl zdiskreditovat spolehlivá
    média, a to tím, že vyprodukovaný obsah nebude dostatečně kvalitní a promyšlený.
</p>
<figure class="figure">
    <img src="/assets/img/uploads/gpt-3-api.jpg" class="figure-img img-fluid rounded" alt="GPT-3 poskytuje API">
    <figcaption class="figure-caption text-center">OpenAI také poskytuje (na žádost) API, které dalo za vznik několika zajímavým porjektům (viz druhý odstavec).</figcaption>
</figure>
<p>Umí psát jako člověk, ale nerozumí tomu, co říká. Na otázku, zda umělá inteligence jednou zcela nahradí živé autory,
    neexistuje jednoznačná odpověď. „Zatím to tak nevypadá, ale v budoucnosti by třeba mohla fungovat jako jeden z
    nástrojů, které má autor k dispozici,“ míní dramaturg David Košťák ze Švandova divadla v Praze.</p>
<p>Mnohé zkušenosti nám zatím ukázaly, že texty vyprodukované čistě počítačem mohou mít jistou úroveň a kvalitu, nicméně
    nesmíme zapomínat i na slabé stránky a rizika plynoucí z používání této technologie. Jak uvádí časopis Wired, umělá
    inteligence zatím nemá na to stát se královnou, ani pro ni psát projevy. Nicméně je jisté, že se tato technologie
    ubírá tím správným směrem, a již nyní lidem denně pomáhá usnadnit jejich práci. A vůbec nevadí, že z ní zatím není
    zrovna Shakespeare.</p>